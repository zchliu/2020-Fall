# 计算机视觉第一次作业报告

## <font face="仿宋" >人工智能82班 刘志成 2183511589</font>

---
### 理论推导

2D卷积与互相关的定义，性质推导与证明；2D卷积的时间复杂度；
2D高斯的可分离性推导；2D高斯核与2D高斯核卷积的解析结果；
2D空间卷积定理的推导；2D频率卷积定理的推导；

##### 相关定义

$$(w \bigotimes f)(m,n) = \sum_{i=-k}^{k} \sum_{j=-k}^{k} w(i,j)f(m+i,n+j)$$

##### 线性性质

$$(w \bigotimes (\alpha f+\beta g))(m,n) \\ =  \sum_{i=-k}^{k} \sum_{j=-k}^{k} w(i,j)(\alpha f(m+i,n+j) + \beta g(m+i,n+j)) \\ = \alpha \sum_{i=-k}^{k} \sum_{j=-k}^{k} w(i,j)f(m+i,n+j) + \beta \sum_{i=-k}^{k} \sum_{j=-k}^{k} w(i,j)g(m+i,n+j) \\ = (\alpha (w \bigotimes f) + \beta (w \bigotimes g))(m,n)$$

<br />

$$(aw+bv) \bigotimes f)(m,n) \\ =  \sum_{i=-k}^{k} \sum_{j=-k}^{k} (aw(i,j)+bv(i,j)) f(m+i,n+j) \\ = a\sum_{i=-k}^{k} \sum_{j=-k}^{k} w(i,j) f(m+i,n+j) + b\sum_{i=-k}^{k} \sum_{j=-k}^{k} v(i,j) f(m+i,n+j) \\ = (a(w \bigotimes f) + b(v \bigotimes f))(m,n) $$

##### 平移不变性

$$f'(m,n) = f(m-m_0,n-n_0) \\ (w \bigotimes f')(m,n) \\ =  \sum_{i=-k}^{k} \sum_{j=-k}^{k} w(i,j)f'(m+i,n+j) \\ =  \sum_{i=-k}^{k} \sum_{j=-k}^{k} w(i,j)f(m+i-m_0,n+j-n_0) \\ = (w \bigotimes f)(m-m_0,n-n_0)$$

##### 卷积的证明类似

##### 时间复杂度

假设图像的长和宽为M和N，卷积核的大小为$k^2$，对于新图像每一个元素，需要计算$k^2$次乘法，因此总的时间复杂度为$MNk^2$

---

### 滤波实验

2D高斯模板的设计（给定方差生成滤波核）；图像的高斯滤波；在高斯滤波中不同边界处理方法实验；
高斯核与高斯核卷积实验；利用两个相同方差的一位行列高斯核卷积生成2D高斯核，利用一维行列高斯对图像进行滤波；不同方差高斯核之差进行滤波；
利用两个高斯核设计图像锐化滤波器核；
图像双边滤波实验；
图像的Fourier变换，显示幅度谱和相位谱；利用高斯滤波器进行图像的频率域滤波；

##### 图像的padding

基本想法就是把大的图像分成8块，左上，左中，左下，上，下，右上，右中，右下然后分别对这8块进行赋值就可以了
```
def padding(img, ud, lr, paddingtype):
    up = ud[0]
    down = ud[1]
    left = lr[0]
    right = lr[1]

    dst_img = np.zeros((img.shape[0] + up + down, img.shape[1] + left + right, 3))
    dst_img[up:up + img.shape[0], left:left + img.shape[1], 0:3] = img

    if paddingtype == "black":
        pass
    if paddingtype == "wrap":
        dst_img[0:up, 0:left, 0:3] = dst_img[img.shape[0]:img.shape[0] + up, img.shape[1]:img.shape[1] + left, 0:3]
        dst_img[up:up + img.shape[0], 0:left, 0:3] = dst_img[up:up + img.shape[0], img.shape[1]:img.shape[1] + left, 0:3]
        dst_img[up + img.shape[0]:up + img.shape[0] + down, 0:left, 0:3] = dst_img[up:up + down, img.shape[1]:img.shape[1] + left, 0:3]
        dst_img[0:up, left:left + img.shape[1], 0:3] = dst_img[img.shape[0]:img.shape[0] + up, left:left + img.shape[1], 0:3]
        dst_img[up + img.shape[0]:up + img.shape[0] + down, left:left + img.shape[1], 0:3] = dst_img[up:up + down, left:left + img.shape[1], 0:3]
        dst_img[0:up, left + img.shape[1]:left + img.shape[1] + right, 0:3] = dst_img[img.shape[0]:img.shape[0] + up, left:left + right, 0:3]
        dst_img[up:up + img.shape[0], left + img.shape[1]:left + img.shape[1] + right, 0:3] = dst_img[up:up + img.shape[0], left:left + right, 0:3]
        dst_img[up + img.shape[0]:up + img.shape[0] + down, left + img.shape[1]:left + img.shape[1] + right, 0:3] = dst_img[up:up + down, left:left + right, 0:3]
    if paddingtype == "copy":
        dst_img[0:up, 0:left, 0:3] = dst_img[up:up + 1, left:left + 1, 0:3]
        dst_img[up:up + img.shape[0], 0:left, 0:3] = dst_img[up:up + img.shape[0], left:left + 1, 0:3]
        dst_img[up + img.shape[0]:up + img.shape[0] + down, 0:left, 0:3] = dst_img[up + img.shape[0] - 1:up + img.shape[0], left:left + 1, 0:3]
        dst_img[0:up, left:left + img.shape[1], 0:3] = dst_img[up:up + 1, left:left + img.shape[1], 0:3]
        dst_img[up + img.shape[0]:up + img.shape[0] + down, left:left + img.shape[1], 0:3] = dst_img[up + img.shape[0] - 1:up + img.shape[0], left:left + img.shape[1], 0:3]
        dst_img[0:up, left + img.shape[1]:left + img.shape[1] + right, 0:3] = dst_img[up:up + 1, left + img.shape[1] - 1:left + img.shape[1], 0:3]
        dst_img[up:up + img.shape[0], left + img.shape[1]:left + img.shape[1] + right, 0:3] = dst_img[up:up + img.shape[0], left + img.shape[1] - 1:left + img.shape[1], 0:3]
        dst_img[up + img.shape[0]:up + img.shape[0] + down, left + img.shape[1]:left + img.shape[1] + right, 0:3] = dst_img[up + img.shape[0] - 1:up + img.shape[0], left + img.shape[1] - 1:left +
                                                                                                                            img.shape[1], 0:3]
    if paddingtype == "reflect":
        dst_img[0:up, 0:left, 0:3] = np.flip(dst_img[up:up + up, left:left + left, 0:3], (0, 1))
        dst_img[up:up + img.shape[0], 0:left, 0:3] = np.flip(dst_img[up:up + img.shape[0], left:left + left, 0:3], 1)
        dst_img[up + img.shape[0]:up + img.shape[0] + down, 0:left, 0:3] = np.flip(dst_img[up + img.shape[0] - down:up + img.shape[0], left:left + left, 0:3], (0, 1))
        dst_img[0:up, left:left + img.shape[1], 0:3] = np.flip(dst_img[up:up + up, left:left + img.shape[1], 0:3], 0)
        dst_img[up + img.shape[0]:up + img.shape[0] + down, left:left + img.shape[1], 0:3] = np.flip(dst_img[up + img.shape[0] - down:up + img.shape[0], left:left + img.shape[1], 0:3], 0)
        dst_img[0:up, left + img.shape[1]:left + img.shape[1] + right, 0:3] = np.flip(dst_img[up:up + up, left + img.shape[1] - right:left + img.shape[1], 0:3], (0, 1))
        dst_img[up:up + img.shape[0], left + img.shape[1]:left + img.shape[1] + right, 0:3] = np.flip(dst_img[up:up + img.shape[0], left + img.shape[1] - right:left + img.shape[1]], 1)
        dst_img[up + img.shape[0]:up + img.shape[0] + down, left + img.shape[1]:left + img.shape[1] + right, 0:3] = np.flip(
            dst_img[up + img.shape[0] - down:up + img.shape[0], left + img.shape[1] - right:left + img.shape[1], 0:3], (0, 1))

    dst_img = cv.convertScaleAbs(dst_img)
    return dst_img
```
图像大小为512*512，padding的宽度为50，效果如下

<img src="https://s1.ax1x.com/2020/10/05/0JyXpF.png" alt="image" border="0">

black

<img src="https://s1.ax1x.com/2020/10/05/0J6wNV.png" alt="image" border="0">

wrap

<img src="https://s1.ax1x.com/2020/10/05/0J6gBR.png" alt="image" border="0">

copy

<img src="https://s1.ax1x.com/2020/10/05/0tkV4H.png" alt="0tkV4H.png" border="0" />

reflect

##### 2D高斯核卷积

这里定义3个函数，分别是生成卷积核的函数，二维卷积的函数以及调用这两个函数的总函数，代码如下

```
# 常数核卷积，边缘填充为0，卷积核为正方形
def conv2(img, kernel):
    img_dim = len(img.shape)

    if img_dim == 3:
        img_row = img.shape[0]
        img_col = img.shape[1]
        img_channel = img.shape[2]

        kernel_size = kernel.shape[0]
        result = np.zeros((img_row, img_col, img_channel))
        ex_img = np.pad(img, ((kernel_size // 2, kernel_size // 2), (kernel_size // 2, kernel_size // 2), (0, 0)), 'constant', constant_values=(0, 0))
        result_row = result.shape[0]
        result_col = result.shape[1]
        result_channel = result.shape[2]
        for i in range(result_row):
            for j in range(result_col):
                for k in range(result_channel):
                    result[i, j, k] = np.sum(ex_img[i:i + kernel_size, j:j + kernel_size, k] * kernel)
    elif img_dim == 2:
        img_row = img.shape[0]
        img_col = img.shape[1]
        kernel_size = kernel.shape[0]
        result = np.zeros((img_row, img_col))
        ex_img = np.pad(img, ((kernel_size // 2, kernel_size // 2), (kernel_size // 2, kernel_size // 2)), 'constant', constant_values=(0, 0))
        result_row = result.shape[0]
        result_col = result.shape[1]
        for i in range(result_row):
            for j in range(result_col):
                result[i, j] = np.sum(ex_img[i:i + kernel_size, j:j + kernel_size] * kernel)
    result = cv.convertScaleAbs(result)
    return result


# 2D高斯模板的设计（给定方差生成滤波核）
def gaussian_kernel2(kernel_size, sigma):
    gauss_k = np.zeros((kernel_size, kernel_size), np.float32)
    for i in range(kernel_size):
        for j in range(kernel_size):
            norm = (i - kernel_size // 2)**2 + (j - kernel_size // 2)**2
            gauss_k[i, j] = np.exp(-norm / (sigma**2 * 2))
    s = gauss_k.sum()
    gauss_k = gauss_k / s
    return gauss_k


# 图像的高斯滤波
def gauss_filter2(img, kernel_size, sigma):

    kernel = gaussian_kernel2(kernel_size, sigma)
    result = conv2(img, kernel)
    result = cv.convertScaleAbs(result)
    return result.astype(np.uint8)
```

对上述padding过的图像进行阶数为11*11，方差为1的高斯滤波，为了保持修改后的图像和原图像的大小一致，将padding宽度定为5，效果如下

<img src="https://s1.ax1x.com/2020/10/05/0tu89U.png" alt="image" border="0">

black

<img src="https://s1.ax1x.com/2020/10/05/0tuB4K.png" alt="image" border="0">

wrap

<img src="https://s1.ax1x.com/2020/10/05/0tuhUP.png" alt="image" border="0">

copy

<img src="https://s1.ax1x.com/2020/10/05/0tKOQe.png" alt="image" border="0">

reflect

可以看出高斯核卷积过程中用哪一种边界来处理差别不大

##### 1D的高斯核卷积

1D的卷积要分成两步来进行，分别是竖向的卷积核横向的卷积，代码如下

```
def conv1_col(img, kernel):
    img_dim = len(img.shape)

    if img_dim == 3:
        img_row = img.shape[0]
        img_col = img.shape[1]
        img_channel = img.shape[2]
        kernel_size = kernel.shape[0]
        result = np.zeros((img_row, img_col, img_channel))
        # 竖向卷积
        ex_img = np.pad(img, ((kernel_size // 2, kernel_size // 2), (0, 0), (0, 0)), 'constant', constant_values=(0, 0))
        result_row = result.shape[0]
        result_col = result.shape[1]
        result_channel = result.shape[2]
        for i in range(result_row):
            for j in range(result_col):
                for k in range(result_channel):
                    result[i, j, k] = np.sum(ex_img[i:i + kernel_size, j:j + 1, k] * kernel)

    elif img_dim == 2:
        img_row = img.shape[0]
        img_col = img.shape[1]
        kernel_size = kernel.shape[0]

        result = np.zeros((img_row, img_col))
        # 竖向卷积
        ex_img = np.pad(img, ((kernel_size // 2, kernel_size // 2), (0, 0)), 'constant', constant_values=(0, 0))
        result_row = result.shape[0]
        result_col = result.shape[1]
        for i in range(result_row):
            for j in range(result_col):
                result[i, j] = np.sum(ex_img[i:i + kernel_size, j:j + 1] * kernel)

    result = cv.convertScaleAbs(result)
    return result


def conv1_row(img, kernel):
    img_dim = len(img.shape)

    if img_dim == 3:
        img_row = img.shape[0]
        img_col = img.shape[1]
        img_channel = img.shape[2]
        kernel_size = kernel.shape[1]

        result = np.zeros((img_row, img_col, img_channel))
        # 横向卷积
        ex_img = np.pad(img, ((0, 0), (kernel_size // 2, kernel_size // 2), (0, 0)), 'constant', constant_values=(0, 0))
        result_row = result.shape[0]
        result_col = result.shape[1]
        result_channel = result.shape[2]
        for i in range(result_row):
            for j in range(result_col):
                for k in range(result_channel):
                    result[i, j, k] = np.sum(ex_img[i:i + 1, j:j + kernel_size, k] * kernel)

    elif img_dim == 2:
        img_row = img.shape[0]
        img_col = img.shape[1]
        kernel_size = kernel.shape[1]

        result = np.zeros((img_row, img_col))
        # 横向卷积
        ex_img = np.pad(img, ((0, 0), (kernel_size // 2, kernel_size // 2)), 'constant', constant_values=(0, 0))
        result_row = result.shape[0]
        result_col = result.shape[1]
        for i in range(result_row):
            for j in range(result_col):
                result[i, j] = np.sum(ex_img[i:i + 1, j:j + kernel_size // 2] * kernel)

    result = cv.convertScaleAbs(result)
    return result


def gaussian_kernel1(kernel_size, sigma):
    gauss_k = np.zeros((kernel_size, 1), np.float32)
    for i in range(kernel_size):
        norm = (i - kernel_size // 2)**2
        gauss_k[i, 0] = np.exp(-norm / (sigma**2 * 2))
    s = gauss_k.sum()
    gauss_k = gauss_k / s
    return gauss_k


def gauss_filter1(img, kernel_size, sigma):

    kernel = gaussian_kernel1(kernel_size, sigma)
    result = conv1_col(img, kernel)
    result = conv1_row(result, kernel.transpose())
    result = cv.convertScaleAbs(result)
    return result.astype(np.uint8)
```

用11阶方差为1的卷积效果如下

<img src="https://s1.ax1x.com/2020/10/05/0tMD6e.png" alt="image" border="0">

与2D卷积的效果差别不大

##### DoG算子

DoG算子的卷积核就是两个方差不同的高斯核之差，代码如下

```
def DoG_filter(img, kernel_size, sigma1, sigma2):
    kernel1 = gaussian_kernel2(kernel_size, sigma1)
    kernel2 = gaussian_kernel2(kernel_size, sigma2)
    result = conv2(img, kernel1 - kernel2)
    result = cv.convertScaleAbs(result)
    return result.astype(np.uint8)
```

效果如下：

<img src="https://s1.ax1x.com/2020/10/05/0tl7iq.png" alt="image" border="0">

可以看出DoG算子提取的是图像的边缘

##### 图像的锐化

图像的锐化的想法主要是先用高斯卷积核得到模糊的图像，再用原来的图像减去模糊的图像得到细节，最后把细节按一定的比例加回到原图像上就得到了锐化的图像，代码如下：

```
def sharpen_filter(img, kernel_size, sigma, alpha):
    kernel1 = np.zeros((kernel_size, kernel_size))
    kernel1[kernel_size // 2, kernel_size // 2] = 1
    kernel2 = gaussian_kernel2(kernel_size, sigma)
    kernel = (1 + alpha) * kernel1 - alpha * kernel2
    result = conv2(img, kernel)

    result = cv.convertScaleAbs(result)
    return result
```
<img src="https://s1.ax1x.com/2020/10/06/0NMSNq.png" alt="0NMSNq.png" border="0" />

原图像

<img src="https://s1.ax1x.com/2020/10/06/0NKLjg.png" alt="0NKLjg.png" border="0" />

用7阶高斯滤波器，sigma=1，alpha=0.8得到的锐化图像

<img src="https://s1.ax1x.com/2020/10/06/0NKzEn.png" alt="0NKzEn.png" border="0" />

用7阶高斯滤波器，sigma=3，alpha=0.8得到的锐化图像

可以看出，随着sigma的增大，图像的细节越明显，但是图像中的噪点也越多

##### 图像的双边滤波

图像的双边滤波在高斯滤波的基础上考虑到了图像边缘值的影响，是一种非线性滤波，这里的range的权重用了颜色向量的欧氏距离，代码如下：

```
def bilateral_filter(img, kernel_size, sigmas, sigmar):
    img_dim = len(img.shape)

    if img_dim == 3:
        img_row = img.shape[0]
        img_col = img.shape[1]
        img_channel = img.shape[2]

        kernels = gaussian_kernel2(kernel_size, sigmas)
        kernelr = np.zeros((kernel_size, kernel_size))
        kernel = np.zeros((kernel_size, kernel_size))

        result = np.zeros((img_row, img_col, img_channel))
        # ex_img = np.pad(img, ((kernel_size // 2, kernel_size // 2), (kernel_size // 2, kernel_size // 2), (0, 0)), 'constant', constant_values=(0, 0))
        ex_img = padding(img, (kernel_size // 2, kernel_size // 2), (kernel_size // 2, kernel_size // 2), "reflect")
        result_row = result.shape[0]
        result_col = result.shape[1]
        result_channel = result.shape[2]
        for i in range(result_row):
            for j in range(result_col):

                for m in range(0, kernel_size, 1):
                    for n in range(0, kernel_size, 1):
                        kernelr[m, n] = (float(ex_img[i + m, j + n, 0]) - float(ex_img[i + kernel_size // 2, j + kernel_size // 2, 0]))**2 + (float(ex_img[i + m, j + n, 1]) - float(
                            ex_img[i + kernel_size // 2, j + kernel_size // 2, 1]))**2 + (float(ex_img[i + m, j + n, 2]) - float(ex_img[i + kernel_size // 2, j + kernel_size // 2, 2]))**2
                kernelr = np.exp(-kernelr / (2 * sigmar**2))
                kernel = kernels * kernelr
                s = np.sum(kernel)
                kernel = kernel / s
                for k in range(result_channel):
                    result[i, j, k] = np.sum(ex_img[i:i + kernel_size, j:j + kernel_size, k] * kernel)

    result = cv.convertScaleAbs(result)
    return result
```

效果如下

<img src="https://s1.ax1x.com/2020/10/06/0NjgJ0.png" alt="0NjgJ0.png" border="0" />

原图像

<img src="https://s1.ax1x.com/2020/10/06/0NvemQ.png" alt="0NvemQ.png" border="0" />

阶数为7，sigmas=2，sigmar=36的双边滤波


##### 图像的傅里叶变换和频率域滤波

离散傅里叶变换的公式如下：

$$X(k,l) = {1 \over MN} \sum_{m=0}^{M-1} \sum_{n=0}^{N-1}x[m,n]e^{-jk{2\pi \over M }m}e^{-jl{2\pi \over N }n} \space \space k=0,1...M-1,l=0,1...N-1$$

离散傅里叶逆变换的公式如下：

$$x[m,n] = \sum_{k=0}^{M-1} \sum_{l=0}^{N-1}X(k,l)e^{jk{2\pi \over M }m}e^{jl{2\pi \over N }n} \space \space m=0,1...M-1,n=0,1...N-1$$

由于没有使用FFT以及python的循环实在很慢，暂时用库函数np.fft.fft2来做，输入图像为一个灰度图

<img src="https://s1.ax1x.com/2020/10/07/0andxS.png" alt="image" border="0">

原图像

<img src="https://s1.ax1x.com/2020/10/07/0an65q.png" alt="image" border="0">

幅度谱

<img src="https://s1.ax1x.com/2020/10/07/0anhMF.png" alt="image" border="0">

相位谱







