# 计算机视觉第二次作业报告

## <font face="仿宋" >人工智能82班 刘志成 2183511589</font>

---

相关代码已上传至我的github仓库：
https://github.com/zchliu/2020-Fall

### 实验题目

图像变换（图像、编程语言自选）
图像的参数化几何变换原理
图像的前向变换(forward warping)和逆向变换(inverse warping)
图像的下抽样原理和图像的内插方法原理（近邻插值和双线性插值）
完成图像的几何变换实验，包括：平移变换；旋转变换；欧式变换；相似变换；仿射变换；投影变换；
完成图像的高斯金字塔表示与拉普拉斯金字塔表示，讨论前置低通滤波和抽样频率的关系

特征检测
基于高斯一阶微分的图像梯度（幅值图和方向图），分析高斯方差对图像梯度的影响；
掌握canny边缘检测原理，完成图像的边缘检测实验，展示每个环节的处理结果（梯度图，NMS，边缘链接）；
掌握Harris焦点检测原理，完成图像的角点检测实验，分析窗口参数对角点检测的影响，讨论角点检测的不变性，等变性和定位精度；

### 图像变换

假设一幅图像由$f(m,n)$表示，图像的几何变换可以由一个射影矩阵H来描述

$$H = \left[\begin{matrix}
    h_{11} & h_{12} & h_{13}  \\
    h_{21} & h_{22} & h_{23}  \\
    h_{31} & h_{32} & h_{33}  \\
\end{matrix}\right]$$

因此，对于图像当中的每一个点$[x,y,z]^T$，经过摄影矩阵处理后为$[x',y',z']^T = H[x,y,z]^T$，用齐次坐标表示为$[x',y',1]^T = \lambda H[x,y,1]^T$，则变换后的图像$f'(m,n)$满足如下关系：

$$I'(x',y') = I(x,y)$$

图像变换有不同的具体类型，但所有的变换均可以用一个H矩阵来描述，因此代码统一如下：

```
def geotransform(img, H, center):
    img_dim = len(img.shape)

    if img_dim == 3:
        row = img.shape[0]
        col = img.shape[1]
        channel = img.shape[2]

        result = np.zeros((row, col, channel))

        for i in range(row):
            for j in range(col):

                src_pos = np.dot(H, np.array([[i], [j], [1]]) - center) + center

                if (abs(src_pos[2, 0] - 1) > epsilon):

                    # 转换成齐次坐标
                    src_pos[0, 0] = src_pos[0, 0] / (src_pos[2, 0] + epsilon)
                    src_pos[1, 0] = src_pos[1, 0] / (src_pos[2, 0] + epsilon)
                    src_pos[2, 0] = 1

                src_pos = src_pos[0:2, 0:1]

                if 0 < src_pos[0, 0] < row - 1 and 0 < src_pos[1, 0] < col - 1:

                    left_up = np.array([[int(src_pos[0, 0])], [int(src_pos[1, 0])]])
                    right_up = np.array([[int(src_pos[0, 0])], [int(src_pos[1, 0]) + 1]])
                    left_down = np.array([[int(src_pos[0, 0]) + 1], [int(src_pos[1, 0])]])
                    right_down = np.array([[int(src_pos[0, 0]) + 1], [int(src_pos[1, 0]) + 1]])

                    for k in range(channel):

                        # 双线性插值
                        result[i, j, k] = img[left_up[0, 0], left_up[1, 0], k] * abs(right_down - src_pos)[0, 0] * abs(right_down - src_pos)[1, 0] + img[left_down[0, 0], left_down[1, 0], k] * abs(
                            right_up - src_pos)[0, 0] * abs(right_up - src_pos)[1, 0] + img[right_up[0, 0], right_up[1, 0], k] * abs(left_down - src_pos)[0, 0] * abs(
                                left_down - src_pos)[1, 0] + img[right_down[0, 0], right_down[1, 0], k] * abs(left_up - src_pos)[0, 0] * abs(left_up - src_pos)[1, 0]

        return result.astype(np.uint8)
```

##### 平移变换

假设图像的平移向量为$[t_x,t_y]^T$，则相应的H矩阵为：

$$H = \left[\begin{matrix}
    1 & 0 & t_x  \\
    0 & 1 & t_y  \\
    0 & 0 & 1  \\
\end{matrix}\right]$$


将图像横向平移50个单位，纵向平移25个单位的效果如下：

<img src="https://s1.ax1x.com/2020/10/20/BpbCsx.png" alt="image" border="0">

##### 旋转变换

假设图像按照逆时针方向旋转角度为$\alpha$，则相应的H矩阵为：

$$H = \left[\begin{matrix}
    cos \alpha & sin \alpha & 0  \\
    -sin \alpha & cos \alpha & 0  \\
    0 & 0 & 1  \\
\end{matrix}\right]$$

在旋转过程中，由于在找原像素点的时候有可能出现横纵坐标为小数的坐标点，因此我们用双线性插值的办法来求横纵坐标为小数的像素点

<img src="https://s1.ax1x.com/2020/10/20/Bpq1j1.png" alt="image" border="0">

假设待插值点与附近的4个整数值像素点所形成的面积如图所示为S1，S2，S3，S4，则相应的点P的灰度值为

$$I(P) = {S1 \over S1 + S2 + S3 + S4} I(Q_{21}) + {S2 \over S1 + S2 + S3 + S4} I(Q_{11}) + {S3 \over S1 + S2 + S3 + S4} I(Q_{22}) + {S4 \over S1 + S2 + S3 + S4} I(Q_{12})$$


逆时针旋转30度的效果图如下：

<img src="https://s1.ax1x.com/2020/10/20/BpLaZV.png" alt="image" border="0">

##### 欧式变换

欧式变换可以看成是旋转变换和平移变换的叠加，假设旋转角为$\alpha$，平移向量为$[t_x,t_y]^T$，则相应的H矩阵为：

$$H = \left[\begin{matrix}
    cos \alpha & sin \alpha & t_x  \\
    -sin \alpha & cos \alpha & t_y \\
    0 & 0 & 1  \\
\end{matrix}\right]$$

图像逆时针旋转30度，向左平移50，向上平移25的效果如下：

<img src="https://s1.ax1x.com/2020/10/20/BpOytS.png" alt="image" border="0">

##### 尺度变换

尺度变换就是在原来旋转的基础上乘以一个尺度因子，假设旋转角为$\alpha$，平移向量为$[t_x,t_y]^T$，图像变为原来的s倍，则相应的H矩阵为：

$$H = \left[\begin{matrix}
    s*cos \alpha & s*sin \alpha & t_x  \\
    -s*sin \alpha & s*cos \alpha & t_y \\
    0 & 0 & 1  \\
\end{matrix}\right]$$

图像逆时针旋转30度，缩小为原来的5/6，向左平移50，向上平移25的效果如下：

<img src="https://s1.ax1x.com/2020/10/20/BpvJYT.png" alt="image" border="0">

##### 仿射变换

仿射变换中，相应的H矩阵如下：

$$H = \left[\begin{matrix}
    h_{11} & h_{12} & t_x  \\
    h_{21} & h_{22} & t_y \\
    0 & 0 & 1  \\
\end{matrix}\right]$$

左上角的2*2矩阵为任意值

用矩阵$\left[\begin{matrix}
    1.1 & 0.1 & 25  \\
    0.2 & 1.2 & 15 \\
    0 & 0 & 1  \\
\end{matrix}\right]$处理的结果如下：

<img src="https://s1.ax1x.com/2020/10/21/B9n1FU.png" alt="image" border="0">

##### 投影变换

投影变换中，H矩阵为任意3*3可逆矩阵

$$H = \left[\begin{matrix}
    h_{11} & h_{12} & h_{13}  \\
    h_{21} & h_{22} & h_{23}  \\
    h_{31} & h_{32} & h_{33}  \\
\end{matrix}\right]$$

用矩阵$\left[\begin{matrix}
    1.1 & 0.1 & 25  \\
    0.2 & 1.2 & 15 \\
    0.001 & 0.002 & 1.003  \\
\end{matrix}\right]$处理的结果如下：

<img src="https://s1.ax1x.com/2020/10/21/B9uZtO.png" alt="image" border="0">

### 图像金字塔

##### 高斯金字塔

高斯金字塔用原图像的不同大小的图像来表示，每一个图像看成是金字塔的一层，原图像认为是在第0层，可以先对原图像用高斯核做卷积，然后再下采样就可以得到上一层的图像，重复上述步骤可以得到每一层大小为下面一层四分之一的图像，把这些图像重叠起来就可以得到高斯金字塔

假设$x_0(n),x_1(n),...,x_l(n)$为高斯金字塔里面的每一层图像，$y_0(n),y_1(n),...,y_l(n)$为每一层图像经过模糊处理之后，采样之前的图像，则具体过程如下：

$$y_0(n) = x_0(n) * g(n,\sigma _0) \\ x_1(n) = y_0(2n) \\ y_1(n) = x_1(n) * g(n,\sigma _1) \\ x_2(n) = y_1(2n) \\ ... \\ y_{l-1}(n) = x_{l-1}(n) * g(n,\sigma _{l-1}) \\ x_l(n) = y_{l-1}(2n)$$

要注意的是，虽然再采样之前都用高斯核进行了模糊处理，但是每一次模糊处理所用高斯核的方差却不同，这主要是由于每一次图像的大小发生了变化，看下面一个两层高斯金字塔的例子：

$$y_1(n) = x_1(n) * g(n,\sigma _1) \\ = y_0(2n) * g_1(n, \sigma _1) \\ =  x_0(2n) * g(2n,\sigma _0) * g(n, \sigma _1)$$

上述是对第一层的图像$x_1(n)$进行模糊处理，用到的高斯核是$g(n, \sigma _1)$，为了保证每一次对图像的模糊程度相同，$g(n, \sigma _1)$应该等于$g(2n, \sigma _0)$，由高斯核函数的公式易得$\sigma _1 = {1 \over 2} \sigma _0$，因此，方差$\sigma$满足：

$$\sigma _0 = 2\sigma _1 = 4\sigma _2 = ...$$

代码如下：

```
def down_sample(img):

    img_dim = len(img.shape)

    if img_dim == 3:
        row = img.shape[0]
        col = img.shape[1]
        channel = img.shape[2]

        dst_img = np.zeros((row // 2, col // 2, channel))
        for i in range(row // 2):
            for j in range(col // 2):

                src_pos = np.array([[2 * i], [2 * j]])
                for k in range(channel):

                    dst_img[i, j, k] = img[src_pos[0, 0], src_pos[1, 0], k]

        dst_img = cv.convertScaleAbs(dst_img)
        return dst_img.astype(np.uint8)


def gaussian_pyramid(img, level, kernel_size, sigma):

    result = []
    dst_img = img.copy()
    dst_sigma = sigma
    result.append(dst_img)
    for i in range(level):
        dst_img = filter.gauss_filter(dst_img, kernel_size, dst_sigma)
        dst_img = down_sample(dst_img)
        dst_sigma = dst_sigma / 2
        result.append(dst_img)

    return result
```

用初始$\sigma = 2$处理结果如下:

<img src="https://s1.ax1x.com/2020/10/21/BP17jS.png" alt="BP17jS.png" border="0" />
<img src="https://s1.ax1x.com/2020/10/21/BP3PuF.png" alt="BP3PuF.png" border="0" />
<img src="https://s1.ax1x.com/2020/10/21/BP3ENR.png" alt="BP3ENR.png" border="0" />
<img src="https://s1.ax1x.com/2020/10/21/BP3ujO.png" alt="BP3ujO.png" border="0" />
<img src="https://s1.ax1x.com/2020/10/21/BP33Ed.png" alt="BP33Ed.png" border="0" />

##### 拉普拉斯金字塔

拉普拉斯金字塔用常用于图像的还原，一个图像先经过下采样，再通过上采样和高斯核填充0值得部分可以得到原图像的模糊形式，将原图像与这个图象相减就可以得到图像的细节，应用这个思想就可以得到拉普拉斯金字塔，具体过程如下图：

<img src="https://s1.ax1x.com/2020/10/22/BPLA6H.png" alt="BPLA6H.png" border="0" />

代码如下：

```
def up_sample(img, kernel_size, sigma):

    img_dim = len(img.shape)

    if img_dim == 3:
        row = img.shape[0]
        col = img.shape[1]
        channel = img.shape[2]

        dst_img = np.zeros((2 * row, 2 * col, channel))
        for i in range(2 * row):
            for j in range(2 * col):
                if i % 2 == 0 and j % 2 == 0:
                    for k in range(channel):
                        dst_img[i, j, k] = img[i // 2, j // 2, k]

        ex_img = filter.padding(dst_img, (kernel_size // 2, kernel_size // 2), (kernel_size // 2, kernel_size // 2), "reflect")
        gauss_k = filter.gaussian_kernel(kernel_size, sigma)

        for i in range(2 * row):
            for j in range(2 * col):
                for k in range(channel):
                    if dst_img[i, j, k] == 0:
                        s = np.sum((ex_img[i:i + kernel_size, j:j + kernel_size, k] != 0) * gauss_k)
                        dst_img[i, j, k] = np.sum(ex_img[i:i + kernel_size, j:j + kernel_size, k] * gauss_k) / s

        dst_img = cv.convertScaleAbs(dst_img)
        return dst_img.astype(np.uint8)

def laplace_pyramid(img, level, kernel_size, sigma):

    result = []
    current_img = img.copy()
    for i in range(level):
        down_img = down_sample(current_img, 1, 1)
        up_img = up_sample(down_img, kernel_size, sigma)
        detail_img = current_img - up_img
        result.append(detail_img)
        current_img = down_img

    result.append(current_img)
    return result
```

对图像上采样用5阶高斯核，方差为1进行插值，最后得到的拉普拉斯金字塔效果如下：

<img src="https://s1.ax1x.com/2020/10/22/BPLJns.png" alt="BPLJns.png" border="0" />
<img src="https://s1.ax1x.com/2020/10/22/BPLt7q.png" alt="BPLt7q.png" border="0" />
<img src="https://s1.ax1x.com/2020/10/22/BPLaNV.png" alt="BPLaNV.png" border="0" />
<img src="https://s1.ax1x.com/2020/10/22/BPLrjJ.png" alt="BPLrjJ.png" border="0" />
<img src="https://s1.ax1x.com/2020/10/22/BPL2Ax.png" alt="BPL2Ax.png" border="0" />
<img src="https://s1.ax1x.com/2020/10/22/BPLh9O.png" alt="BPLh9O.png" border="0" />

由于在下采样过程中没有先用高斯核滤去高频信号，因此在图像边缘处有高频噪声发生混叠，但这并不影响图像还原

```
def build_from_laplace_pyramid(laplace_pyramid, kernel_size, sigma):

    length = len(laplace_pyramid)
    current_img = laplace_pyramid[length - 1]

    for i in range(length - 2, -1, -1):
        up_img = up_sample(current_img, kernel_size, sigma)
        current_img = up_img + laplace_pyramid[i]

    return current_img.astype(np.uint8)
```

上述代码将生成的拉普拉斯金字塔进行了还原，结果和原图像一模一样

<img src="https://s1.ax1x.com/2020/10/22/BPO2rj.png" alt="BPO2rj.png" border="0" />

### Canny边缘检测

Canny边缘检测主要包括三个步骤，第一步是用Derivative of Gaussian核卷积原图像，分为x轴卷积和y轴卷积，生成相应的幅度图和梯度图，第二步针对第一步生成的图像的幅度谱做非极大值抑制，把较粗的线条变细，第三步为边缘链接，设定两个阈值，先找到图像当中高于高阈值的部分，再寻找他们的相邻点，如果相邻点高于低阈值则把他也给加入到边缘集合里面，重复上述步骤直到不再有新的点加入边缘集合

##### 梯度图

用高斯核的导数构成的核进行卷积，得到图像边缘的梯度

```
def DeriveOG_filter(img, kernel_size, sigma):

    kernel_x = np.zeros((kernel_size, kernel_size))
    kernel_y = np.zeros((kernel_size, kernel_size))
    for i in range(kernel_size):
        for j in range(kernel_size):
            norm = (i - kernel_size // 2)**2 + (j - kernel_size // 2)**2
            kernel_x[i, j] = (j - kernel_size // 2) * np.exp(-norm / (sigma**2 * 2))
            kernel_y[i, j] = (i - kernel_size // 2) * np.exp(-norm / (sigma**2 * 2))

    s_x = np.sum(abs(kernel_x)) / 2
    s_y = np.sum(abs(kernel_y)) / 2
    kernel_x = kernel_x / s_x
    kernel_y = kernel_y / s_y

    img_x = conv(img, kernel_x, "warp")
    img_y = conv(img, kernel_y, "warp")

    img_magnitude = np.sqrt(img_x**2 + img_y**2)

    return img_magnitude, img_x, img_y
```

用7阶高斯核，方差为3卷积的效果如下

<img src="https://s1.ax1x.com/2020/10/23/BAYtW4.png" alt="BAYtW4.png" border="0" />

图像有较粗的边缘，接下来我们用非极大值抑制来使线条变细


##### 非极大值抑制

为了更准确的识别出边缘，这里的非极大值抑制算法的两个相邻点采用双线性插值的办法获得，采用简单的3-Neiborhood算法，有效率更高的算法可以见论文《Efficient Non-Maximum Suppression》

代码如下：

```
def NMS(img_magnitude, img_x, img_y):

    ex_img = np.pad(img_magnitude, ((1, 1), (1, 1)), 'constant', constant_values=(0, 0))
    dst_img = np.zeros((img_magnitude.shape[0], img_magnitude.shape[1]))

    for i in range(img_magnitude.shape[0]):
        for j in range(img_magnitude.shape[1]):

            if img_magnitude[i, j] > epsilon:
                gradiant = np.array([[img_x[i, j] / img_magnitude[i, j]], [img_y[i, j] / img_magnitude[i, j]]])
                forward_pos = np.array([[i + gradiant[1, 0]], [j + gradiant[0, 0]]])
                # gradiant[0] 为左右方向，gradiant[1]为上下方向

                left_up_f = np.array([[int(forward_pos[0, 0])], [int(forward_pos[1, 0])]])
                right_up_f = np.array([[int(forward_pos[0, 0])], [int(forward_pos[1, 0] + 1)]])
                left_down_f = np.array([[int(forward_pos[0, 0]) + 1], [int(forward_pos[1, 0])]])
                right_down_f = np.array([[int(forward_pos[0, 0]) + 1], [int(forward_pos[1, 0] + 1)]])

                forward_I = ex_img[left_up_f[0, 0], left_up_f[1, 0]] * abs(right_down_f - forward_pos)[0, 0] * abs(
                    right_down_f - forward_pos)[1, 0] + ex_img[left_down_f[0, 0], left_down_f[1, 0]] * abs(right_up_f - forward_pos)[0, 0] * abs(
                        right_up_f - forward_pos)[1, 0] + ex_img[right_up_f[0, 0], right_up_f[1, 0]] * abs(left_down_f - forward_pos)[0, 0] * abs(
                            left_down_f - forward_pos)[1, 0] + ex_img[right_down_f[0, 0], right_down_f[1, 0]] * abs(left_up_f - forward_pos)[0, 0] * abs(left_up_f - forward_pos)[1, 0]

                backward_pos = np.array([[i - gradiant[1, 0]], [j - gradiant[0, 0]]])
                left_up_b = np.array([[int(backward_pos[0, 0])], [int(backward_pos[1, 0])]])
                right_up_b = np.array([[int(backward_pos[0, 0])], [int(backward_pos[1, 0]) + 1]])
                left_down_b = np.array([[int(backward_pos[0, 0]) + 1], [int(backward_pos[1, 0])]])
                right_down_b = np.array([[int(backward_pos[0, 0]) + 1], [int(backward_pos[1, 0]) + 1]])

                backward_I = ex_img[left_up_b[0, 0], left_up_b[1, 0]] * abs(right_down_b - backward_pos)[0, 0] * abs(
                    right_down_b - backward_pos)[1, 0] + ex_img[left_down_b[0, 0], left_down_b[1, 0]] * abs(right_up_b - backward_pos)[0, 0] * abs(
                        right_up_b - backward_pos)[1, 0] + ex_img[right_up_b[0, 0], right_up_b[1, 0]] * abs(left_down_b - backward_pos)[0, 0] * abs(
                            left_down_b - backward_pos)[1, 0] + ex_img[right_down_b[0, 0], right_down_b[1, 0]] * abs(left_up_b - backward_pos)[0, 0] * abs(left_up_b - backward_pos)[1, 0]

                if img_magnitude[i, j] > forward_I and img_magnitude[i, j] > backward_I:
                    dst_img[i, j] = img_magnitude[i, j]

    return dst_img
```

效果如下：

<img src="https://s1.ax1x.com/2020/10/23/BANZvj.png" alt="BANZvj.png" border="0" />

图中原本的粗线条基本上已经变细了，接下来根据两个阈值来选取边缘点进行二值化

##### 边缘链接

代码如下

```
def Hysteresis_thresholding(img, threshold1, threshold2):

    row = img.shape[0]
    col = img.shape[1]

    dst_img = np.zeros((row, col))
    seen = np.zeros((row, col))

    for i in range(row):
        for j in range(col):

            if img[i, j] > threshold1:
                dst_img[i, j] = 255

    new_add = 100000
    while new_add > 5:
        s = 0
        for i in range(row):
            for j in range(col):
                if dst_img[i, j] == 255:
                    seen[i, j] = 1
                    for k in range(i - 1, i + 2):
                        for l in range(j - 1, j + 2):
                            if 0 <= k < row and 0 <= l < col and seen[k, l] != 1:
                                if img[k, l] > threshold2:
                                    dst_img[k, l] = 255
                                    seen[k, l] = 1
                                    s += 1
        new_add = s

    return dst_img
```

效果如下：

<img src="http://ww1.sinaimg.cn/mw690/006cOKN6gy1gjzmp85v4kj30hx0iyac7.jpg"/>

线条还是粗了点，不过已经把边缘很好的表示出来了

### 角点检测

本题做Harris角点检测，计算步骤如下：

1. 计算图像x,y方向的梯度Ix，Iy
   $I_x = G_\sigma^x*I, I_y = G_\sigma^y*I$

2. 计算每个像素点梯度的平方
   $I_{x^2} = I_x I_x, I_{y^2} = I_y I_y, I_{xy} = I_x I_y$

3. 计算梯度在每一个像素点的和
   $S_{x^2} = G_{\sigma'} * I_{x^2},S_{y^2} = G_{\sigma'} * I_{y^2},S_{xy} = G_{\sigma'} * I_{xy}$ 

4. 定义在每个像素点的矩阵H
   $H = \left[\begin{matrix}
       S_{x^2}(x,y) & S_{xy}(x,y) \\
       S_{xy}(x,y) & S_{y^2}(x,y)
   \end{matrix}\right]$

5. 计算每个像素的角点响应
   $R = Det(H) - k(trace(H))^2$

6. 设置阈值并进行非极大值抑制

代码如下：
```
def Harris_corner(img, kernel_size1, sigma1, kernel_size2, sigma2, k):

    # img_x为x方向上的梯度
    # img_y为y方向上的梯度
    kernel_x = np.zeros((kernel_size1, kernel_size1))
    kernel_y = np.zeros((kernel_size1, kernel_size1))
    for i in range(kernel_size1):
        for j in range(kernel_size1):
            norm = (i - kernel_size1 // 2)**2 + (j - kernel_size1 // 2)**2
            kernel_x[i, j] = (j - kernel_size1 // 2) * np.exp(-norm / (sigma1**2 * 2))
            kernel_y[i, j] = (i - kernel_size1 // 2) * np.exp(-norm / (sigma1**2 * 2))

    s_x = np.sum(abs(kernel_x)) / 2
    s_y = np.sum(abs(kernel_y)) / 2
    kernel_x = kernel_x / s_x
    kernel_y = kernel_y / s_y

    Ix = filter.conv(img, kernel_x, "copy")
    Iy = filter.conv(img, kernel_y, "copy")

    Ix2 = Ix * Ix
    Iy2 = Iy * Iy
    Ixy = Ix * Iy

    Sx2 = filter.gauss_filter(Ix2, kernel_size2, sigma2)
    Sy2 = filter.gauss_filter(Iy2, kernel_size2, sigma2)
    Sxy = filter.gauss_filter(Ixy, kernel_size2, sigma2)

    row = Sx2.shape[0]
    col = Sx2.shape[1]

    R = np.zeros((row, col))

    for i in range(row):
        for j in range(col):

            R[i, j] = Sx2[i, j] * Sy2[i, j] - Sxy[i, j]**2 - k * (Sx2[i, j] + Sy2[i, j])**2

    Rmax = np.max(R)
    dst_corner = np.zeros((row, col))
    img_with_corner = img.copy()
    for i in range(row):
        for j in range(col):
            if R[i, j] < 0.01 * Rmax:
                R[i, j] = 0

    for i in range(1, row - 1):
        for j in range(1, col - 1):

            if R[i, j] > 0:
                if R[i, j] >= R[i - 1, j - 1] and R[i, j] >= R[i - 1, j] and R[i, j] >= R[i - 1, j + 1] and R[i, j] >= R[i, j - 1] and R[i, j] >= R[i, j + 1] and R[i, j] >= R[i + 1, j - 1] and R[
                        i, j] >= R[i + 1, j] and R[i, j] >= R[i + 1, j + 1]:
                    dst_corner[i, j] = 255
                    img_with_corner = cv.circle(img, (j, i), kernel_size2 // 2, (255, 0, 0), 1)

    return img_with_corner
```

效果如下：


<img src="https://s1.ax1x.com/2020/10/25/BekLeH.png" alt="BekLeH.png" border="0" />
